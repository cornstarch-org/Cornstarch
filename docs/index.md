---
description: "Cornstarch: Multimodal Model Training Framework"
hide:
  - toc
  - navigation
---
<div align="center">
<img src="assets/images/cornstarch.svg">
<h1><strong>Cornstarch</strong></h1>
<h2>Build, Train, and Run Your Own Multimodal Model</h2>
</div>
---

Cornstarch is a multimodal model training framework that allows you to create your own multimodal model from a set of HuggingFace unimodal models, train, or use it.

# Documentation Organization
- [Getting Started](getting_started/installation.md): Instructions on installation and setup.
- [Creating a multimodal LLM](using_cornstarch/creating_mllm.md): How to create a multimodal LLM from unimodal models.
- [Preprocessing multimodal inputs](using_cornstarch/preprocessing_inputs.md): How to preprocess muiltimodal inputs to run a multimodal LLM.
- [Training a multimodal LLM](using_cornstarch/training_mllm.md): How to train a multimodal LLM using Cornstarch.
- [Multimodal LLM Parallelization](parallelization/index.md): How to parallelize a multimodal LLM training.

# Research Works
Below is a list of works powered by Cornstarch.

- [Oobleck](https://github.com/SymbioticLab/Oobleck): resilient distributed training using pipeline template

## Contact
Insu Jang (insujang@umich.edu)